{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b841c449",
   "metadata": {},
   "source": [
    "# Using Little VGG for emotion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c9627",
   "metadata": {},
   "source": [
    "Training Emotion Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e81416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24264 images belonging to 6 classes.\n",
      "Found 4616 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization,Conv2D,MaxPooling2D\n",
    "import os\n",
    "\n",
    "num_classes=6\n",
    "img_rows,img_cols=48,48\n",
    "batch_size=18\n",
    "\n",
    "train_data_dir='./Dataset/train'\n",
    "validation_data_dir='./Dataset/validation'\n",
    "\n",
    "#data augmentation\n",
    "train_datagen=ImageDataGenerator(\n",
    "             rescale=1./255,\n",
    "             rotation_range=30,\n",
    "             shear_range=0.5,\n",
    "             width_shift_range=0.6,\n",
    "             height_shift_range=0.3,\n",
    "             horizontal_flip=True,\n",
    "             fill_mode='nearest')\n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            color_mode='grayscale',\n",
    "            target_size=(img_rows,img_cols),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True)\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            color_mode='grayscale',\n",
    "            target_size=(img_rows,img_cols),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fd63a",
   "metadata": {},
   "source": [
    "Keras Little VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e1e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation,Flatten,Dropout,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3051c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 4,757,478\n",
      "Trainable params: 4,753,254\n",
      "Non-trainable params: 4,224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(512,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2bfe7",
   "metadata": {},
   "source": [
    "# Creating my own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec4143c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1348/1348 [==============================] - 928s 677ms/step - loss: 2.2897 - accuracy: 0.1909 - val_loss: 1.7568 - val_accuracy: 0.1799\n",
      "Epoch 2/12\n",
      "1348/1348 [==============================] - 915s 679ms/step - loss: 1.7547 - accuracy: 0.2185 - val_loss: 1.7294 - val_accuracy: 0.2493\n",
      "Epoch 3/12\n",
      "1348/1348 [==============================] - 678s 503ms/step - loss: 1.7297 - accuracy: 0.2327 - val_loss: 1.8059 - val_accuracy: 0.1882\n",
      "Epoch 4/12\n",
      "1348/1348 [==============================] - 518s 384ms/step - loss: 1.7054 - accuracy: 0.2563 - val_loss: 1.6603 - val_accuracy: 0.3140\n",
      "Epoch 5/12\n",
      "1348/1348 [==============================] - 382s 283ms/step - loss: 1.6767 - accuracy: 0.2756 - val_loss: 1.7374 - val_accuracy: 0.3203\n",
      "Epoch 6/12\n",
      "1348/1348 [==============================] - 386s 286ms/step - loss: 1.6229 - accuracy: 0.3295 - val_loss: 1.4279 - val_accuracy: 0.4638\n",
      "Epoch 7/12\n",
      "1348/1348 [==============================] - 384s 285ms/step - loss: 1.5393 - accuracy: 0.3902 - val_loss: 1.3737 - val_accuracy: 0.4425\n",
      "Epoch 8/12\n",
      "1348/1348 [==============================] - 383s 284ms/step - loss: 1.4900 - accuracy: 0.4120 - val_loss: 1.3379 - val_accuracy: 0.4475\n",
      "Epoch 9/12\n",
      "1348/1348 [==============================] - 384s 285ms/step - loss: 1.4445 - accuracy: 0.4316 - val_loss: 1.2581 - val_accuracy: 0.4842\n",
      "Epoch 10/12\n",
      "1348/1348 [==============================] - 408s 302ms/step - loss: 1.4116 - accuracy: 0.4444 - val_loss: 1.1812 - val_accuracy: 0.5536\n",
      "Epoch 11/12\n",
      "1348/1348 [==============================] - 390s 290ms/step - loss: 1.3746 - accuracy: 0.4697 - val_loss: 1.1334 - val_accuracy: 0.5618\n",
      "Epoch 12/12\n",
      "1348/1348 [==============================] - 393s 291ms/step - loss: 1.3785 - accuracy: 0.4645 - val_loss: 1.1043 - val_accuracy: 0.5790\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint=ModelCheckpoint('./emotion_little_vgg.h5',\n",
    "                          monitor='val_loss',\n",
    "                          mode='min',\n",
    "                          save_best_only=True,\n",
    "                          verbode=1)\n",
    "\n",
    "earlystop=EarlyStopping(monitor='val_loss',\n",
    "                       min_delta=0,\n",
    "                       patience=3,\n",
    "                       verbose=1,\n",
    "                       restore_best_weights=True)\n",
    "\n",
    "reduce_lr=ReduceLROnPlateau(monitor='val_loss',\n",
    "                            factor=0.2,\n",
    "                            patience=3,\n",
    "                            verbose=1,min_delta=0.0001)\n",
    "\n",
    "callbacks=(earlystop,checkpoint,reduce_lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "nb_train_samples=24264\n",
    "nb_validation_samples=4616\n",
    "epochs=12\n",
    "\n",
    "history=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples//batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        validation_steps=nb_validation_samples//batch_size,\n",
    "        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9358d92",
   "metadata": {},
   "source": [
    "# Creating confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58247650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4616 images belonging to 6 classes.\n",
      "Confusion Matrix\n",
      "[[   0    0  491    0    0    0]\n",
      " [   0    0  637    0    0    2]\n",
      " [   0    0  872    0    0    7]\n",
      " [   0    0 1210    0    0    6]\n",
      " [   0    0  591    0    0    3]\n",
      " [   0    0  796    0    0    1]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.00      0.00      0.00       491\n",
      "        Fear       0.00      0.00      0.00       639\n",
      "       Happy       0.19      0.99      0.32       879\n",
      "     Neutral       0.00      0.00      0.00      1216\n",
      "         Sad       0.00      0.00      0.00       594\n",
      "    Surprise       0.05      0.00      0.00       797\n",
      "\n",
      "    accuracy                           0.19      4616\n",
      "   macro avg       0.04      0.17      0.05      4616\n",
      "weighted avg       0.05      0.19      0.06      4616\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "nb_train_samples=24264\n",
    "nb_validation_samples=4616\n",
    "\n",
    "#recreate our validation generator with shuffle=false\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            color_mode='grayscale',\n",
    "            target_size=(img_rows,img_cols),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)\n",
    "class_labels=validation_generator.class_indices\n",
    "class_labels={v: k for k,v in class_labels.items()}\n",
    "classes=list(class_labels.values())\n",
    "\n",
    "# confusion matrix and classification report\n",
    "Y_pred=model.predict(validation_generator,nb_validation_samples // batch_size+1)\n",
    "y_pred=np.argmax(Y_pred,axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes,y_pred))\n",
    "print('Classification Report')\n",
    "target_names=list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes,y_pred,target_names=target_names,zero_division='warn',digits=2))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix=confusion_matrix(validation_generator.classes,y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks=np.arange(len(classes))\n",
    "_=plt.xticks(tick_marks,classes,rotation=90)\n",
    "_=plt.yticks(tick_marks,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c30e2",
   "metadata": {},
   "source": [
    "# Loading my saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9482ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier=load_model(\"emotion_little_vgg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02931019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g my class labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
